{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Santiago8888/Kin/blob/master/Cat_dog_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BViE2ZUEwLsi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "df218c0f-28db-4be1-bab1-91757f0c0103"
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"dzetaa\",\"key\":\"00431f0f6a6a7725bdbe7b053b8ce916\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.2)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "mkdir: cannot create directory ‘.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhdmtkXPxGj-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "a9211992-26ce-4098-98ff-75e4d48dff57"
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition -p /content"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n",
            "Downloading test.zip to /content\n",
            " 95% 257M/271M [00:02<00:00, 92.3MB/s]\n",
            "100% 271M/271M [00:03<00:00, 93.5MB/s]\n",
            "Downloading train.zip to /content\n",
            " 97% 529M/544M [00:09<00:00, 49.4MB/s]\n",
            "100% 544M/544M [00:09<00:00, 58.1MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/111k [00:00<?, ?B/s]\n",
            "100% 111k/111k [00:00<00:00, 115MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO1eH3K0xQR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \\*.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaP3CiKRfErH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzjuycSfyC_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir training\n",
        "! mkdir testing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlEmvD7gyGwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mv train training/train\n",
        "! mv test testing/test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etAjaBjwyK3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82nVlAk7yTY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        " \n",
        "dirpath = os.getcwd()\n",
        "# TODO: Define transforms for the training data and testing data\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "# Pass transforms in here, then run the next cell to see how the transforms look\n",
        "train_data = datasets.ImageFolder(dirpath + '/training', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(dirpath + '/testing', transform=test_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1usfBXjGyZJL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ea824392-e0c8-46df-f6fc-ff930c6accbe"
      },
      "source": [
        "model = models.densenet121(pretrained=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 32342954/32342954 [00:01<00:00, 28178969.82it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-aqdNVsygGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "from collections import OrderedDict\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(1024, 500)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('fc2', nn.Linear(500, 2)),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))\n",
        "    \n",
        "model.classifier = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8bMNn2-yjYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7dbe79c9-8bd9-4e0d-e278-c25c26050c73"
      },
      "source": [
        "import time\n",
        "for device in ['cpu', 'cuda']:\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    # Only train the classifier parameters, feature parameters are frozen\n",
        "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for ii, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "        # Move input and label tensors to the GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        outputs = model.forward(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if ii==3:\n",
        "            break\n",
        "        \n",
        "    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device = cpu; Time per batch: 6.485 seconds\n",
            "Device = cuda; Time per batch: 0.009 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NN16RUsyzua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use GPU if it's available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.densenet121(pretrained=True)\n",
        "\n",
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "model.classifier = nn.Sequential(nn.Linear(1024, 256),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.2),\n",
        "                                 nn.Linear(256, 2),\n",
        "                                 nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Only train the classifier parameters, feature parameters are frozen\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n",
        "\n",
        "model.to(device);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPx6wWVBLZnm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f360c83-8d74-4216-a188-420e6687cf0e"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdJH-YVyze7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 5\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in trainloader:\n",
        "        steps += 1\n",
        "        # Move input and label tensors to the default device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        logps = model.forward(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if steps % print_every == 0:\n",
        "            test_loss = 0\n",
        "            accuracy = 0\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in testloader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    logps = model.forward(inputs)\n",
        "                    batch_loss = criterion(logps, labels)\n",
        "                    \n",
        "                    test_loss += batch_loss.item()\n",
        "                    \n",
        "                    # Calculate accuracy\n",
        "                    ps = torch.exp(logps)\n",
        "                    top_p, top_class = ps.topk(1, dim=1)\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "                    \n",
        "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
        "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
        "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
        "            running_loss = 0\n",
        "            model.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a_nNk2VfIDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'checkpoint.pth')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZCB_27AiZZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1214
        },
        "outputId": "9f2ade71-26be-4446-e482-4f97134ca9fd"
      },
      "source": [
        "model.eval()\n",
        "for inputs, labels in testloader:\n",
        "  print(labels)\n",
        "  print(inputs.size())\n",
        "  inputs, labels = inputs.to(device), labels.to(device)\n",
        "  logps = model.forward(inputs)\n",
        "  print(logps)\n",
        "  break"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "torch.Size([64, 3, 224, 224])\n",
            "tensor([[   0.0000,  -76.6500],\n",
            "        [   0.0000,  -66.7262],\n",
            "        [   0.0000,  -92.6436],\n",
            "        [   0.0000,  -70.3295],\n",
            "        [   0.0000,  -80.6685],\n",
            "        [   0.0000,  -87.3395],\n",
            "        [   0.0000,  -68.8893],\n",
            "        [   0.0000,  -76.4385],\n",
            "        [   0.0000,  -87.5351],\n",
            "        [   0.0000,  -69.9157],\n",
            "        [   0.0000,  -66.4588],\n",
            "        [   0.0000,  -72.5665],\n",
            "        [   0.0000,  -67.7540],\n",
            "        [   0.0000,  -74.4275],\n",
            "        [   0.0000,  -76.7239],\n",
            "        [   0.0000,  -72.6007],\n",
            "        [   0.0000,  -84.4645],\n",
            "        [   0.0000,  -79.9156],\n",
            "        [   0.0000,  -75.8944],\n",
            "        [   0.0000,  -77.1081],\n",
            "        [   0.0000,  -74.5948],\n",
            "        [   0.0000,  -81.5074],\n",
            "        [   0.0000,  -84.8498],\n",
            "        [   0.0000,  -62.5305],\n",
            "        [   0.0000,  -72.7568],\n",
            "        [   0.0000,  -61.9519],\n",
            "        [   0.0000,  -62.8684],\n",
            "        [   0.0000,  -73.0257],\n",
            "        [   0.0000,  -54.2462],\n",
            "        [   0.0000,  -80.6378],\n",
            "        [   0.0000,  -53.6082],\n",
            "        [   0.0000,  -63.4233],\n",
            "        [   0.0000,  -64.0420],\n",
            "        [   0.0000,  -62.6938],\n",
            "        [   0.0000,  -76.4630],\n",
            "        [   0.0000,  -68.2634],\n",
            "        [   0.0000,  -65.0525],\n",
            "        [   0.0000,  -63.7169],\n",
            "        [   0.0000,  -83.2466],\n",
            "        [   0.0000,  -77.8979],\n",
            "        [   0.0000,  -85.4692],\n",
            "        [   0.0000,  -79.8888],\n",
            "        [   0.0000,  -61.9565],\n",
            "        [   0.0000,  -78.8481],\n",
            "        [   0.0000,  -88.4039],\n",
            "        [   0.0000,  -62.0668],\n",
            "        [   0.0000,  -74.5886],\n",
            "        [   0.0000,  -60.1266],\n",
            "        [   0.0000,  -78.7989],\n",
            "        [   0.0000,  -72.4419],\n",
            "        [   0.0000,  -74.2490],\n",
            "        [   0.0000,  -62.3784],\n",
            "        [   0.0000,  -69.7134],\n",
            "        [   0.0000,  -77.5951],\n",
            "        [   0.0000,  -79.6477],\n",
            "        [   0.0000,  -60.0677],\n",
            "        [   0.0000,  -62.0477],\n",
            "        [   0.0000,  -83.3750],\n",
            "        [   0.0000,  -77.0262],\n",
            "        [   0.0000,  -89.5719],\n",
            "        [   0.0000, -110.0980],\n",
            "        [   0.0000,  -69.8289],\n",
            "        [   0.0000,  -48.5897],\n",
            "        [   0.0000,  -89.6798]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}