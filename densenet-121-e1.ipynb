{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Santiago8888/Kin/blob/dev/densenet-121-e1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0k5tSAQbEM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"dzetaa\",\"key\":\"00431f0f6a6a7725bdbe7b053b8ce916\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI60qV8PbOOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition -p /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3lSDnHubSTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \\*.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qom81t-ibl2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir training\n",
        "! mkdir testing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGnbAbUYbpbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mv train training/train\n",
        "! mv test testing/test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7ZEPrAkbva-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHBouJuv3EMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKeZNcb6bztu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        " \n",
        "dirpath = os.getcwd()\n",
        "# TODO: Define transforms for the training data and testing data\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "# Pass transforms in here, then run the next cell to see how the transforms look\n",
        "train_data = datasets.ImageFolder(dirpath + '/training', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(dirpath + '/testing', transform=test_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc9CeVTwb3Jw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.densenet121(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIgSlsK0b99f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "from collections import OrderedDict\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(1024, 500)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('fc2', nn.Linear(500, 2)),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))\n",
        "    \n",
        "model.classifier = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6YSQlfpcAN3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "33e40d14-e671-4caa-ce85-956fdf8c71fa"
      },
      "source": [
        "import time\n",
        "for device in ['cpu', 'cuda']:\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    # Only train the classifier parameters, feature parameters are frozen\n",
        "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for ii, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "        # Move input and label tensors to the GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        outputs = model.forward(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if ii==3:\n",
        "            break\n",
        "        \n",
        "    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device = cpu; Time per batch: 6.139 seconds\n",
            "Device = cuda; Time per batch: 0.008 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujqfqbM3cOuO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e30bcd5-b535-4833-810a-2daf502a025a"
      },
      "source": [
        "import time\n",
        "for device in ['cuda']:\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    # Only train the classifier parameters, feature parameters are frozen\n",
        "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for ii, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "        # Move input and label tensors to the GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        outputs = model.forward(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if ii==3:\n",
        "            break\n",
        "        \n",
        "    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device = cuda; Time per batch: 0.008 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clHocjCdcZ_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use GPU if it's available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.densenet121(pretrained=True)\n",
        "\n",
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "model.classifier = nn.Sequential(nn.Linear(1024, 256),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.2),\n",
        "                                 nn.Linear(256, 2),\n",
        "                                 nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Only train the classifier parameters, feature parameters are frozen\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n",
        "\n",
        "model.to(device);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoUJbEZgceyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ii, (inputs, labels) in enumerate(trainloader):\n",
        "  print (ii, labels, labels.size())\n",
        "print (ii*64)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QNeWwsxchnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 5\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in trainloader:\n",
        "        steps += 1\n",
        "        # Move input and label tensors to the default device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        logps = model.forward(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if steps % print_every == 0:\n",
        "            test_loss = 0\n",
        "            accuracy = 0\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in testloader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    logps = model.forward(inputs)\n",
        "                    batch_loss = criterion(logps, labels)\n",
        "                    \n",
        "                    test_loss += batch_loss.item()\n",
        "                    \n",
        "                    # Calculate accuracy\n",
        "                    ps = torch.exp(logps)\n",
        "                    top_p, top_class = ps.topk(1, dim=1)\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "                    \n",
        "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
        "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
        "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
        "            running_loss = 0\n",
        "            model.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuBCJEBmiE4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls training/train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0WukLYsmq9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bd2875f-1e0a-415f-fdcc-bb33ef3a6f18"
      },
      "source": [
        "i = 0\n",
        "j = 0\n",
        "k = 0\n",
        "for file in os.listdir('training/train'):\n",
        "  if 'cat' in file:\n",
        "#    if i < 11250:\n",
        "      i += 1\n",
        "#      os.rename('training/train/'+file, 'train/cats/'+file)\n",
        "  elif 'dog' in file:\n",
        "#    if i < 11250:\n",
        "      j += 1\n",
        "#      os.rename('training/train/'+file, 'train/dogs/'+file)      \n",
        "  k += 1\n",
        "        \n",
        "  \n",
        "print(i, j, k)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtOj5fFgyFNU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "28359bf3-a97b-47c4-accd-e48e9ad0fe01"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\t       testing\t train\t   train.zip\n",
            "sample_submission.csv  test.zip  training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYrwObXQyQ4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY8y_s9uykfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPSinFNmqC0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir train/cats\n",
        "! mkdir train/dogs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-RUSvyzra_h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "655db2ec-492c-4cff-f14e-8f780a59352b"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLbyJrhPpF7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.rename(\"training/train/cat.11752.jpg\", \"training/train/cts/cat.11752.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll9-WtYlylX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \\*.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPIPg87jzHPK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "749d9e06-3bdf-410a-b587-bc7ec2cbfedd"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'test': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f8RBy7B0Gsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r test.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0ytsLJP0c_s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "9c972bbb-166e-4fa3-8a72-808d198d54b1"
      },
      "source": [
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition -p /content"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading test.zip to /content\n",
            " 98% 266M/271M [00:02<00:00, 160MB/s]\n",
            "100% 271M/271M [00:02<00:00, 137MB/s]\n",
            "Downloading train.zip to /content\n",
            " 98% 532M/544M [00:03<00:00, 212MB/s]\n",
            "100% 544M/544M [00:03<00:00, 168MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/111k [00:00<?, ?B/s]\n",
            "100% 111k/111k [00:00<00:00, 114MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBQPLDPz0h21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm test.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqUmiMp90nl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \\*.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bseReH5x0ssg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5wV9lly04Ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv train images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjFa5Twd07iF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir test\n",
        "!mkdir train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69LvTzsV1PfN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d03a32fe-ff25-42d3-f65a-0d1982de01c3"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images\ttest  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkvRWlnM1Vii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d1fcea76-46f0-41ac-deff-57a4b63c2d2f"
      },
      "source": [
        "!mkdir train/cats\n",
        "!mkdir train/dogs\n",
        "\n",
        "!mkdir test/cats\n",
        "!mkdir test/dogs"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘train/cats’: File exists\n",
            "mkdir: cannot create directory ‘train/dogs’: File exists\n",
            "mkdir: cannot create directory ‘test/cats’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySUrh2DF1GX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa8c9d62-0deb-4b7f-9441-e6f4d21c193f"
      },
      "source": [
        "cat_counter = 0\n",
        "dog_counter = 0\n",
        "for file in os.listdir('images'):\n",
        "  if 'cat' in file:\n",
        "    if cat_counter < 11250:\n",
        "      os.rename('images/' + file, 'train/cats/' + file)\n",
        "      cat_counter += 1\n",
        "    else:\n",
        "      os.rename('images/' + file, 'test/cats/' + file)\n",
        "  elif 'dog' in file:\n",
        "    if dog_counter < 11250:\n",
        "      os.rename('images/' + file, 'train/dogs/' + file)\n",
        "      dog_counter +=1\n",
        "    else:\n",
        "      os.rename('images/' + file, 'test/dogs/' + file)\n",
        "\n",
        "print(cat_counter, dog_counter)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11250 11250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWuQbCRF3FtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE-4Y1Cp3HVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        " \n",
        "dirpath = os.getcwd()\n",
        "# TODO: Define transforms for the training data and testing data\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "# Pass transforms in here, then run the next cell to see how the transforms look\n",
        "train_data = datasets.ImageFolder('train', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder('test', transform=test_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkskRJBP3VRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ii, (inputs, labels) in enumerate(testloader):\n",
        "  print (ii, labels, labels.size())\n",
        "print (ii*64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5ymfPEX4IzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.densenet121(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw0KAn1E4XdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "from collections import OrderedDict\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(1024, 500)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('fc2', nn.Linear(500, 2)),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))\n",
        "    \n",
        "model.classifier = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqh9nVAV4Yy6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd57249d-4e5c-4eb0-83d1-3e1b765e0c41"
      },
      "source": [
        "import time\n",
        "for device in ['cuda']:\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    # Only train the classifier parameters, feature parameters are frozen\n",
        "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for ii, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "        # Move input and label tensors to the GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        outputs = model.forward(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if ii==3:\n",
        "            break\n",
        "        \n",
        "    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device = cuda; Time per batch: 0.008 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t1NXhAN4eDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1249
        },
        "outputId": "428e46b5-3d36-4fce-d092-749cfa8d8a2b"
      },
      "source": [
        "epochs = 1\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 5\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in trainloader:\n",
        "        steps += 1\n",
        "        # Move input and label tensors to the default device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        logps = model.forward(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if steps % print_every == 0:\n",
        "            test_loss = 0\n",
        "            accuracy = 0\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in testloader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    logps = model.forward(inputs)\n",
        "                    batch_loss = criterion(logps, labels)\n",
        "                    \n",
        "                    test_loss += batch_loss.item()\n",
        "                    \n",
        "                    # Calculate accuracy\n",
        "                    ps = torch.exp(logps)\n",
        "                    top_p, top_class = ps.topk(1, dim=1)\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "                    \n",
        "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
        "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
        "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
        "            running_loss = 0\n",
        "            model.train()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1.. Train loss: 0.367.. Test loss: 0.119.. Test accuracy: 0.962\n",
            "Epoch 1/1.. Train loss: 0.257.. Test loss: 0.106.. Test accuracy: 0.962\n",
            "Epoch 1/1.. Train loss: 0.202.. Test loss: 0.099.. Test accuracy: 0.963\n",
            "Epoch 1/1.. Train loss: 0.213.. Test loss: 0.072.. Test accuracy: 0.973\n",
            "Epoch 1/1.. Train loss: 0.159.. Test loss: 0.106.. Test accuracy: 0.961\n",
            "Epoch 1/1.. Train loss: 0.212.. Test loss: 0.093.. Test accuracy: 0.964\n",
            "Epoch 1/1.. Train loss: 0.169.. Test loss: 0.079.. Test accuracy: 0.969\n",
            "Epoch 1/1.. Train loss: 0.174.. Test loss: 0.058.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.193.. Test loss: 0.055.. Test accuracy: 0.978\n",
            "Epoch 1/1.. Train loss: 0.129.. Test loss: 0.065.. Test accuracy: 0.973\n",
            "Epoch 1/1.. Train loss: 0.125.. Test loss: 0.053.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.125.. Test loss: 0.055.. Test accuracy: 0.977\n",
            "Epoch 1/1.. Train loss: 0.161.. Test loss: 0.064.. Test accuracy: 0.973\n",
            "Epoch 1/1.. Train loss: 0.187.. Test loss: 0.052.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.192.. Test loss: 0.050.. Test accuracy: 0.981\n",
            "Epoch 1/1.. Train loss: 0.142.. Test loss: 0.064.. Test accuracy: 0.975\n",
            "Epoch 1/1.. Train loss: 0.140.. Test loss: 0.051.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.223.. Test loss: 0.065.. Test accuracy: 0.976\n",
            "Epoch 1/1.. Train loss: 0.290.. Test loss: 0.078.. Test accuracy: 0.975\n",
            "Epoch 1/1.. Train loss: 0.171.. Test loss: 0.076.. Test accuracy: 0.970\n",
            "Epoch 1/1.. Train loss: 0.191.. Test loss: 0.071.. Test accuracy: 0.971\n",
            "Epoch 1/1.. Train loss: 0.168.. Test loss: 0.056.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.179.. Test loss: 0.071.. Test accuracy: 0.972\n",
            "Epoch 1/1.. Train loss: 0.118.. Test loss: 0.050.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.208.. Test loss: 0.054.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.148.. Test loss: 0.074.. Test accuracy: 0.970\n",
            "Epoch 1/1.. Train loss: 0.142.. Test loss: 0.051.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.157.. Test loss: 0.051.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.185.. Test loss: 0.063.. Test accuracy: 0.976\n",
            "Epoch 1/1.. Train loss: 0.139.. Test loss: 0.051.. Test accuracy: 0.981\n",
            "Epoch 1/1.. Train loss: 0.149.. Test loss: 0.048.. Test accuracy: 0.981\n",
            "Epoch 1/1.. Train loss: 0.145.. Test loss: 0.071.. Test accuracy: 0.976\n",
            "Epoch 1/1.. Train loss: 0.245.. Test loss: 0.123.. Test accuracy: 0.954\n",
            "Epoch 1/1.. Train loss: 0.220.. Test loss: 0.048.. Test accuracy: 0.984\n",
            "Epoch 1/1.. Train loss: 0.198.. Test loss: 0.047.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.146.. Test loss: 0.058.. Test accuracy: 0.978\n",
            "Epoch 1/1.. Train loss: 0.165.. Test loss: 0.070.. Test accuracy: 0.975\n",
            "Epoch 1/1.. Train loss: 0.179.. Test loss: 0.052.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.245.. Test loss: 0.111.. Test accuracy: 0.959\n",
            "Epoch 1/1.. Train loss: 0.166.. Test loss: 0.051.. Test accuracy: 0.981\n",
            "Epoch 1/1.. Train loss: 0.146.. Test loss: 0.049.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.110.. Test loss: 0.052.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.165.. Test loss: 0.049.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.136.. Test loss: 0.048.. Test accuracy: 0.981\n",
            "Epoch 1/1.. Train loss: 0.145.. Test loss: 0.046.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.120.. Test loss: 0.046.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.125.. Test loss: 0.056.. Test accuracy: 0.977\n",
            "Epoch 1/1.. Train loss: 0.169.. Test loss: 0.048.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.161.. Test loss: 0.046.. Test accuracy: 0.983\n",
            "Epoch 1/1.. Train loss: 0.121.. Test loss: 0.046.. Test accuracy: 0.983\n",
            "Epoch 1/1.. Train loss: 0.125.. Test loss: 0.045.. Test accuracy: 0.984\n",
            "Epoch 1/1.. Train loss: 0.185.. Test loss: 0.055.. Test accuracy: 0.979\n",
            "Epoch 1/1.. Train loss: 0.190.. Test loss: 0.056.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.203.. Test loss: 0.065.. Test accuracy: 0.972\n",
            "Epoch 1/1.. Train loss: 0.186.. Test loss: 0.046.. Test accuracy: 0.985\n",
            "Epoch 1/1.. Train loss: 0.179.. Test loss: 0.045.. Test accuracy: 0.983\n",
            "Epoch 1/1.. Train loss: 0.124.. Test loss: 0.046.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.179.. Test loss: 0.046.. Test accuracy: 0.985\n",
            "Epoch 1/1.. Train loss: 0.174.. Test loss: 0.044.. Test accuracy: 0.983\n",
            "Epoch 1/1.. Train loss: 0.124.. Test loss: 0.056.. Test accuracy: 0.977\n",
            "Epoch 1/1.. Train loss: 0.139.. Test loss: 0.045.. Test accuracy: 0.985\n",
            "Epoch 1/1.. Train loss: 0.137.. Test loss: 0.044.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.143.. Test loss: 0.043.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.112.. Test loss: 0.049.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.200.. Test loss: 0.046.. Test accuracy: 0.985\n",
            "Epoch 1/1.. Train loss: 0.135.. Test loss: 0.062.. Test accuracy: 0.973\n",
            "Epoch 1/1.. Train loss: 0.168.. Test loss: 0.049.. Test accuracy: 0.984\n",
            "Epoch 1/1.. Train loss: 0.119.. Test loss: 0.042.. Test accuracy: 0.984\n",
            "Epoch 1/1.. Train loss: 0.137.. Test loss: 0.055.. Test accuracy: 0.977\n",
            "Epoch 1/1.. Train loss: 0.135.. Test loss: 0.043.. Test accuracy: 0.986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKKoXcv-A7SU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'densenet-121-1e.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IEKWjYPBIAE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "a1a14f3b-a604-46ed-90d0-5b8eb32994d2"
      },
      "source": [
        "ResNeXt-101-32x8d"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-112-de6c3adc07d2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ResNeXt-101-32x8d\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k-GkphQFVl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "af90f3b7-7d8b-47ee-ea44-a121f556f8f8"
      },
      "source": [
        "model = models.ResNeXt-101-32x8d(pretrained=True)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-113-fa1bdc96344e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    model = models.ResNeXt-101-32x8d(pretrained=True)\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqs_MclKFp-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = models.densenet121(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI9kydxJFuc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model2.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "from collections import OrderedDict\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(1024, 500)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('fc2', nn.Linear(500, 2)),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))\n",
        "    \n",
        "model2.classifier = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0Hqm32UGJ9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc920a25-6ce7-464b-a5fc-04a149f31d1f"
      },
      "source": [
        "epochs = 2\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 5\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in trainloader:\n",
        "        steps += 1\n",
        "        # Move input and label tensors to the default device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        logps = model2.forward(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if steps % print_every == 0:\n",
        "            test_loss = 0\n",
        "            accuracy = 0\n",
        "            model2.eval()\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in testloader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    logps = model2.forward(inputs)\n",
        "                    batch_loss = criterion(logps, labels)\n",
        "                    \n",
        "                    test_loss += batch_loss.item()\n",
        "                    \n",
        "                    # Calculate accuracy\n",
        "                    ps = torch.exp(logps)\n",
        "                    top_p, top_class = ps.topk(1, dim=1)\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "                    \n",
        "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
        "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
        "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
        "            running_loss = 0\n",
        "            model2.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2.. Train loss: 0.708.. Test loss: 0.727.. Test accuracy: 0.367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PcXBCUuGenr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "for device in ['cuda']:\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    # Only train the classifier parameters, feature parameters are frozen\n",
        "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "    model2.to(device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}